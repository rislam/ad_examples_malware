import argparse
from aad.malware_aad import *
from aad.data_stream import *
from os import path
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn import svm
from sklearn.metrics import roc_auc_score
from sklearn.base import clone

from sklearn.metrics import f1_score
# from modAL.models import ActiveLearner, Committee

"""python -m baseline.malware.RForestClassifier --datafile "/Users/mislam1/Documents/RA/research-2018/ad_rakib/ad_examples/datasets/anomaly/malware-all/fullsamples/malware-all_1.csv" --val_frac 0"""

class Baseline:
    def __init__(self, parser):
        self.opts = parser
        self.opts.initial_anomaly = 0
        self.opts.labelindex = 1
        self.X_full, self.y_full = read_data_as_matrix(self.opts)
        self.stream = MalwareDataStream(self.X_full, self.y_full, IdServer(initial=0))
        self.test_data = {}
        self.opts.current_yr = 0
        self._test_data()

    def _test_data(self):
        _stream = MalwareDataStream(self.X_full, self.y_full, IdServer(initial=0))
        index = 0
        while not _stream.empty():
            data = _stream.read_next_from_stream()
            self.test_data[2010 + index] = data
            index += 1

    def classification(self, X_train, y_train, X_val=None , y_val=None, estimators=100):
        if self.opts.base_clf == "RF":
            clf = RandomForestClassifier(n_estimators=estimators, random_state=self.opts.seed)
            logger.debug("classifier is ready for use")
        elif self.opts.base_clf == "SVM":
            clf = svm.SVC(probability=True, decision_function_shape='ovo')
        else:
            raise ValueError("sorry we have only RF and SVM. use --base_clf RF or --base_clf SVM")
        clf = clf.fit(X_train, y_train)
        if X_val is not None and X_val.shape[0] > 0:
            y_pred = clf.predict_proba(X_val)
        else:
            y_pred = clf.predict_proba(X_train)
        # print("classification AUC: ", roc_auc_score(y_train, y_pred[:, 1]))
        return clf, y_pred

    def read_data_as_stream(self):
        np.random.seed(self.opts.seed)
        # opts.datafile = path.join(opts.filedir, "datasets/anomaly", opts.datafile)
        # print(opts.datafile)
        training_x = list()
        training_y = list()
        training_ids = list()
        # dynamically add the training years data
        for tr_yr in range(self.opts.train_years):
            training_set = self.stream.read_next_from_stream()
            self.opts.current_yr += 1
            training_x.extend(training_set.x)
            training_y.extend(training_set.y)
            training_ids.extend(training_set.ids)
            print("x, y shape ", len(training_x), len(training_y))
        training_x = np.array(training_x)
        training_y = np.array(training_y)
        training_ids = np.array(training_ids)
        X_train, X_val, y_train, y_val = train_test_split(
            training_x, training_y, test_size=self.opts.val_frac, random_state=self.opts.seed)
        return X_train, y_train, X_val, y_val, self.stream, training_ids

    def evaluate_batch(self):
        """To test the data sets individually for each year"""
        # if split mentioned for clf training
        X_train, y_train, X_val, y_val, stream, training_ids = self.read_data_as_stream()
        self.opts.X_train = X_train
        self.opts.y_train = y_train.reshape(-1, 1)
        self.opts.clf, y_pred = self.classification(X_train, y_train, X_val, y_val)
        self.opts.clf_init = clone(self.opts.clf)
        self.opts.init_x = deepcopy(X_train)
        self.opts.init_y = deepcopy(y_train)
        self.opts.clf_init = self.opts.clf_init.fit(self.opts.init_x, self.opts.init_y)
        # self.adr_classification(y_pred, y_train, training_ids)
        queried_ids = list()
        queries_asked = 0
        logger.debug("testing started")
        while not stream.empty():
            testing_set = stream.read_next_from_stream()
            self.opts.clf = copy(self.opts.clf_init)
            self.opts.clf = self.opts.clf.fit(self.opts.init_x, self.opts.init_y)
            x_test_cur, y_test_cur, ids_test_cur = testing_set.x, testing_set.y, testing_set.ids
            self.opts.x_dim = x_test_cur.shape[1]
            self.opts.y_dim = 1
            self.opts.ids_dim = 1
            y_pred = self.opts.clf.predict_proba(x_test_cur)
            self.opts.combined_data = np.hstack((x_test_cur, y_test_cur.reshape(-1, 1), ids_test_cur.reshape(-1, 1)))
            self.adr_classification(y_pred, y_test_cur, ids_test_cur, budget=self.opts.query_budget)
            self.opts.current_yr += 1
            print("========")


    def evaluate_stream(self):
        """this will evaluate the streaming setting for classifier"""
        X_train, y_train, X_val, y_val, stream, training_ids = self.read_data_as_stream()
        self.opts.X_train = X_train
        self.opts.y_train = y_train.reshape(-1, 1)
        self.opts.clf, y_pred = self.classification(X_train, y_train, X_val, y_val)

        queried_ids = list()
        queries_asked = 0
        self.opts.combined_data = None
        self.opts.initial_anomaly = self.count_discovered_anomalies()
        while not stream.empty():
            testing_set = stream.read_next_from_stream()
            x_test_cur, y_test_cur, ids_test_cur = testing_set.x, testing_set.y, testing_set.ids
            print(x_test_cur.shape, y_test_cur.shape, ids_test_cur.shape)
            current_combined_data = np.hstack((x_test_cur, y_test_cur.reshape(-1, 1), ids_test_cur.reshape(-1, 1)))
            if self.opts.combined_data is None:
                self.opts.combined_data = current_combined_data
                # print(self.opts.combined_data[:2])
            else:
                self.opts.combined_data = np.vstack((self.opts.combined_data, current_combined_data))
            self.opts.x_dim = x_test_cur.shape[1]
            self.opts.y_dim = 1
            self.opts.ids_dim = 1

            # print("shapes of result ", y_pred[:, 1].reshape(-1, 1).shape, testing_set.y.reshape(-1, 1).shape)
            print("self.opts.query_budget_per_window ", self.opts.query_budget_per_window)
            if queries_asked >= self.opts.query_budget:
                print("query budget ended")
                break
            self.adr_stream_classification(x_test_cur, y_test_cur, ids_test_cur, self.opts.query_budget_per_window)

            queries_asked += self.opts.query_budget_per_window
            print("----------------------")
            print("Queried till now %d and discovered %d " %(queries_asked, self.count_discovered_anomalies()))
            print("----------------------")

        # now we will merge and query and update
        if queries_asked < self.opts.query_budget:
            self.adr_stream_classification(
                x_test_cur, y_test_cur,
                ids_test_cur,
                self.opts.query_budget - queries_asked)
        queries_asked += self.opts.query_budget - queries_asked
        print("----------------------")
        print("Queried till now %d and discovered %d " % (queries_asked, self.count_discovered_anomalies()))
        print("----------------------")

    def compute_classification_res(self, y_pred, y_test_cur, ids_test_cur, test=False):
        """anomlay detected count"""
        result = np.hstack((y_pred[:, 1].reshape(-1, 1), y_test_cur.reshape(-1, 1), ids_test_cur.reshape(-1, 1)))
        result = result[result[:, 0].argsort()[::-1]]
        n_anomalies = np.sum(result[:, 1], axis=0)
        adr_result = np.sum(result[result[:, 0] >= 0.5, 1], axis=0)
        if not test:
            print("%d, %d, %f, %.3f" % (
            n_anomalies, adr_result,
            roc_auc_score(y_test_cur, y_pred[:, 1])),
            f1_score(y_test_cur, y_pred[:, 1]))
            logger.debug(
                "Test n_a %d, adr %d, auc %.3f, f1 %.3f" % (n_anomalies,
                                                            adr_result,
                                                            roc_auc_score(y_test_cur, y_pred[:, 1]),
                                                            f1_score(y_test_cur, y_pred[:, 1])))
            # print("#anomalies: %d discovered anomalies %d AUC score %f" %(n_anomalies, adr_result - self.opts.initial_anomaly, roc_auc_score(y_test_cur, y_pred[:, 1])))
        else:
            # print("#anomalies: %d discovered anomalies %d AUC score %f" % (n_anomalies, adr_result, roc_auc_score(y_test_cur, y_pred[:, 1])))
            print("%d, %d, %f, %.3f" % (
                n_anomalies, adr_result,
                roc_auc_score(y_test_cur, y_pred[:, 1])),
                  f1_score(y_test_cur, y_pred[:, 1]))
            logger.debug(
                "Test n_a %d, adr %d, auc %.3f, f1 %.3f" % (n_anomalies,
                                                            adr_result,
                                                            roc_auc_score(y_test_cur, y_pred[:, 1]),
                                                            f1_score(y_test_cur, y_pred[:, 1])))

            # logger.debug("Test n_a %d, adr %d, auc %.3f" % (n_anomalies, adr_result, roc_auc_score(y_test_cur, y_pred[:, 1])))
            # print("%d, %d, %f" % (n_anomalies, adr_result, roc_auc_score(y_test_cur, y_pred[:, 1])))
        return roc_auc_score(y_test_cur, y_pred[:, 1])

    def adr_classification(self, y_pred, y_test_cur, ids_test_cur, budget=100):
        """the data contains the predicted result in column 0 an ground truth in column 1.
        We are picking top 200 data points based on the o/p of classifier and report the results."""
        logger.debug("w/o feedbacks")
        self.compute_classification_res(y_pred, y_test_cur, ids_test_cur)
        self.evaluate()
        temp_auc = list()
        if self.opts.with_feedback == 1:
            self.opts.initial_anomaly = self.count_discovered_anomalies()
            x_eval_cur = np.copy(self.opts.combined_data[:, :self.opts.x_dim])
            y_eval_cur = np.copy(self.opts.combined_data[:, self.opts.x_dim:self.opts.x_dim + self.opts.y_dim])
            ids_eval_cur = np.copy(self.opts.combined_data[:, self.opts.x_dim + self.opts.y_dim:])
            self.opts.clf = clone(self.opts.clf_init)
            self.opts.clf = self.opts.clf.fit(self.opts.init_x, self.opts.init_y)
            print("with feedbacks")
            for i in range(budget):
                x_test_cur = self.opts.combined_data[:, :self.opts.x_dim]
                y_test_cur = self.opts.combined_data[:, self.opts.x_dim:self.opts.x_dim + self.opts.y_dim]
                ids_test_cur = self.opts.combined_data[:, self.opts.x_dim + self.opts.y_dim:]
                y_pred = self.opts.clf.predict_proba(x_test_cur)
                result = np.hstack((y_pred[:, 1].reshape(-1, 1), y_test_cur.reshape(-1, 1), ids_test_cur.reshape(-1, 1)))
                result = result[result[:, 0].argsort()[::-1]]
                n_anomalies = np.sum(result[:, 1], axis=0)
                adr_result = np.sum(result[:self.opts.find_top, 0] >=0.5, axis=0)
                self.opts.X_train = np.vstack((self.opts.X_train, self.opts.combined_data[self.opts.combined_data[:, -1] == int(result[0, 2]), :self.opts.x_dim]))
                self.opts.y_train = np.vstack((self.opts.y_train, self.opts.combined_data[self.opts.combined_data[:, -1] == result[0, 2], self.opts.x_dim:self.opts.x_dim + 1]))
                # print("combined data shape before deletion: ", self.opts.combined_data.shape)
                self.opts.combined_data = np.delete(self.opts.combined_data, np.where(self.opts.combined_data[:, -1] == result[0, 2]), axis=0)
                self.opts.clf, _ = self.classification(self.opts.X_train, self.opts.y_train)
                y_eval_pred = self.opts.clf.predict_proba(x_eval_cur)
                if i % 25 == 0:
                    temp_auc.append(self.compute_classification_res(y_eval_pred, y_eval_cur, ids_eval_cur, test=True))
            self.opts.initial_anomaly = 0
            print(temp_auc)
            self.evaluate()

    def evaluate(self):
        cur_yr = self.opts.current_yr
        while (cur_yr < 7):
            curr_test_data = self.test_data[2010 + cur_yr - 1]
            y_test_pred = self.opts.clf.predict_proba(curr_test_data.x)
            y_true, ids_test_cur = curr_test_data.y, curr_test_data.ids
            self.compute_classification_res(y_test_pred, y_true, ids_test_cur, test=True)
            cur_yr += 1

    def adr_stream_classification(self, x_test_cur, y_test_cur, ids_test_cur, budget=100):
        """the data contains the predicted result in column 0 an ground truth in column 1.
        We are picking top 200 data points based on the o/p of classifier and report the results."""

        """combined data contains the unlabeled data as it comes as a stream
        x_train, y_train is preserving the labeled data points in particular"""
        for i in range(budget):
            x_test_cur = self.opts.combined_data[:, :self.opts.x_dim]
            y_test_cur = self.opts.combined_data[:, self.opts.x_dim:self.opts.x_dim + self.opts.y_dim]
            ids_test_cur = self.opts.combined_data[:, self.opts.x_dim + self.opts.y_dim:]
            # print ("streaming x_test_cur: ", x_test_cur.shape)
            y_pred = self.opts.clf.predict_proba(x_test_cur)
            result = np.hstack((y_pred[:, 1].reshape(-1, 1), y_test_cur.reshape(-1, 1), ids_test_cur.reshape(-1, 1)))
            result = result[result[:, 0].argsort()[::-1]]
            n_anomalies = np.sum(result[:, 1], axis=0)
            # adr_result = np.sum(result[:self.opts.find_top, 0] >=0.5, axis=0)
            # print("top anomalous ", result[0])
            # print("selection shape ", self.opts.combined_data[self.opts.combined_data[:, -1] == result[0, 2], :self.opts.x_dim].shape)
            self.opts.X_train = np.vstack((self.opts.X_train, self.opts.combined_data[self.opts.combined_data[:, -1] == int(result[0, 2]), :self.opts.x_dim]))
            # print("predicted %f and true is %d (%d)" %(result[0, 0], result[0, 1], result[0, 2] + 2))
            # print(self.opts.y_train.shape)
            # print(self.opts.combined_data[self.opts.combined_data[:, -1] == result[0, 2], self.opts.x_dim:self.opts.x_dim + 1].shape)
            self.opts.y_train = np.vstack((self.opts.y_train, self.opts.combined_data[self.opts.combined_data[:, -1] == result[0, 2], self.opts.x_dim:self.opts.x_dim + 1]))
            # print("combined data shape before deletion: ", self.opts.combined_data.shape)
            self.opts.combined_data = np.delete(self.opts.combined_data, np.where(self.opts.combined_data[:, -1] == result[0, 2]), axis=0)
            if i % 25 == 0:
                # print("combined data shape now: ", self.opts.combined_data.shape)
                # print("training data shape now: ", self.opts.X_train.shape)
                self.count_discovered_anomalies()
            if self.opts.with_feedback == 1:
                # print("feedback is on")
                self.opts.clf, _ = self.classification(self.opts.X_train, self.opts.y_train)
        # print("ended, i=%d, budget=%d" %(i, budget))

    def count_discovered_anomalies(self):
        """count how many anomalies are there in the training set now"""
        adr_result = np.sum(self.opts.y_train[:, 0], axis=0)
        r = adr_result - self.opts.initial_anomaly
        print ("no anomalies discovered : ", r)
        return r

if __name__ == '__main__':
    logger = logging.getLogger(__name__)
    dir_create("./temp/experiments")

    parser = ArgumentParser()
    parser.add_argument("--filedir", action="store", default="",
                        help="Folder for input files")
    parser.add_argument("--cachedir", action="store", default="",
                        help="Folder where the generated models will be cached for efficiency")
    parser.add_argument("--plotsdir", action="store", default="",
                        help="Folder for output plots")
    parser.add_argument("--resultsdir", action="store", default="",
                        help="Folder where the generated metrics will be stored")
    parser.add_argument("--train_years", action="store", default=1,
                        help="determine the training years")
    parser.add_argument("--datafile", type=str, default="", required=False,
                        help="Original data in CSV format. This is used when runtype is 'regular'")
    parser.add_argument("--header", action="store_true", default=True,
                        help="Whether input file has header row")
    parser.add_argument("--startcol", action="store", type=int, default=2,
                        help="Starting column (1-indexed) for data in input CSV")
    parser.add_argument("--val_frac", action="store", type=float, default=0.1,
                        help="What fraction to use for validation")
    parser.add_argument("--seed", action="store", type=int, default=100,
                        help="random seed to use for this evaluation")
    parser.add_argument("--base_clf", action="store", type=str, default="RF",
                        help="classifier to use for this evaluation")
    parser.add_argument("--find_top", action="store", type=int, default=200,
                        help="find anomalies in top 'n' data points")
    parser.add_argument("--query_budget", action="store", type=int, default=100,
                        help="how many queries we will ask in total")
    parser.add_argument("--query_budget_per_window", action="store", type=int, default=50,
                        help="how many queries we will ask per window")
    parser.add_argument("--with_feedback", action="store", type=int, default=0,
                        help="Are we considering the feedbacks?")
    parser.add_argument("--log_file", type=str, default="", required=False,
                        help="File path to debug logs")
    parser.add_argument("--debug", action="store_true", default=True,
                        help="Whether to enable output of debug statements")

    parser = parser.parse_args()
    configure_logger(parser)
    print(parser)
    baseline = Baseline(parser)
    baseline.evaluate_batch()
    # baseline.evaluate_stream()
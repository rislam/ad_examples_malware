import numpy as np
from argparse import ArgumentParser
from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score


class Result():
    def __init__(self, alg=None, dataset=None):
        self.auc_list = list()
        self.f1_list = list()
        self.precision_list = list()
        self.recall_list = list()
        self.alg = alg
        self.dataset_name = dataset

    def __str__(self):
        print("AUC: ", self.auc_list)
        print("F1 : ", self.f1_list)
        print("Prec:", self.precision_list)
        print("Reca:", self.recall_list)
        return ""



def print_results(experiment):
    """ Print the results in a nice format."""
    f1_results_map = experiment.opts.results_f1
    adr_results_map = experiment.opts.results_adr
    f1_result = list() # n_algos X years
    adr_result = list()  # n_algos X years
    for i in range (2012, 2017):
        f1_result.extend(f1_results_map["2012_" + str(i)])
        adr_result.extend(adr_results_map["2012_" + str(i)])

    print("F1  Scores: ", f1_result)
    print("ADR Scores: ", adr_result)


def get_all_metrics(y_true, y_pred):
    ascore = compute_auc(y_true, y_pred)
    f1 = compute_f1(y_true, y_pred)
    precision = compute_precision(y_true, y_pred)
    recall = compute_recall(y_true, y_pred)
    print("%.4f %.4f %.4f %.4f" %(ascore, f1, precision, recall))
    return ascore, f1, precision, recall


def compute_auc(y_true, y_pred):
    ascore = roc_auc_score(y_true, y_pred)
    return ascore


def compute_precision(y_true, y_pred):
    precision = precision_score(y_true, y_pred)
    return precision


def compute_recall(y_true, y_pred):
    recall = recall_score(y_true, y_pred)
    return recall


def predict_proba(self, Z_):
    """
    Make predictions on new dataset.

    INPUT   (1) array 'Z_': new data set (M samples by D features)
    OUTPUT  (2) array 'preds': label predictions (M samples by 1)
    """
    # Data shape
    M, D = Z_.shape

    # If classifier is trained, check for same dimensionality
    if self.is_trained:
        assert self.train_data_dim == D

    # Call scikit's predict function
    preds = self.clf.predict_proba(Z_)

    # Return predictions array
    return preds


def compute_f1(y_true, y_pred):
    """compute F1 Score for the learner"""
    score = f1_score(y_true, y_pred, average='macro')
    return score

def get_anomalies(n_anomaly, n_nominal, ratio=0.1):
    """pick anomalies to preserve the percentage of the dataset"""
    if ratio == 0.1:
        return int(n_nominal / 9)
    else:
        return int((ratio / (1 - ratio)) * n_nominal)

def get_seed(seed, c_run_id):
    """
    Compute the seed for this run, helps to reproduce the result
    :param seed:
    :param c_run_id:
    :return:
    """
    return seed + c_run_id * 100

def parse_arguments():
    """parse all the arguments"""
    parser = ArgumentParser()
    parser.add_argument("--filedir", action="store", default="",
                        help="Folder for input files")
    parser.add_argument("--cachedir", action="store", default="",
                        help="Folder where the generated models will be cached for efficiency")
    parser.add_argument("--plotsdir", action="store", default="",
                        help="Folder for output plots")
    parser.add_argument("--resultsdir", action="store", default="",
                        help="Folder where the generated metrics will be stored")
    parser.add_argument("--train_years", action="store", type=int, default=1,
                        help="determine the training years")
    parser.add_argument("--datafile", type=str, default="", required=False,
                        help="Original data in CSV format. This is used when runtype is 'regular'")
    parser.add_argument("--header", action="store_true", default=True,
                        help="Whether input file has header row")
    parser.add_argument("--startcol", action="store", type=int, default=2,
                        help="Starting column (1-indexed) for data in input CSV")
    parser.add_argument("--val_frac", action="store", type=float, default=0.1,
                        help="What fraction to use for validation")
    parser.add_argument("--seed", action="store", type=int, default=5,
                        help="random seed to use for this evaluation")
    parser.add_argument("--base_clf", action="store", type=str, default="RF",
                        help="classifier to use for this evaluation")
    parser.add_argument("--find_top", action="store", type=int, default=200,
                        help="find anomalies in top 'n' data points")
    parser.add_argument("--n_query", action="store", type=int, default=100,
                        help="how many queries we will ask in total")
    parser.add_argument("--query_budget_per_window", action="store", type=int, default=50,
                        help="how many queries we will ask per window")
    parser.add_argument("--with_feedback", action="store", type=int, default=1,
                        help="Are we considering the feedbacks?")
    parser.add_argument("--query_strategy", action="store", type=int, default=0,
                        help="Are we considering the feedbacks?")
    parser.add_argument("--starting", action="store", type=int, default=0,
                        help="only pre-train (0), feed-backed model(1), or full data(2)?")
    parser.add_argument("--weighted_update", action="store", type=int, default=0,
                        help="wighted update based on the KL divergence")
    parser.add_argument("--debug", action="store_true", default=True,
                        help="Whether to enable output of debug statements")
    parser.add_argument("--log_file", type=str, default="", required=False,
                        help="File path to debug logs")
    parser.add_argument("--n_runs", type=int, default=1, required=False,
                        help="running experiment multiple times")
    parser.add_argument("--vary_param", type=int, default=0, required=False,
                        help="which one is the varying params when we want to plot acorss years")
    parser.add_argument("--train_scratch", action="store_true",
                        help="train it from scratch w/o previous learned model")
    parser.add_argument("--libact-us", action="store_true",
                        help="libact uncertainty sampling")
    parser.add_argument("--libact-qbq", action="store_true",
                        help="libact query by committee")
    parser.add_argument("--libact-hs", action="store_true",
                        help="libact hierarchical sampling")


    return parser.parse_args()
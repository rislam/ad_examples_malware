import numpy as np
from argparse import ArgumentParser
from sklearn.metrics import f1_score


def compute_f1(y_true, y_pred):
    """compute F1 Score for the learner"""
    y_pred[y_pred[:] >= 0.5] = 1
    y_pred[y_pred[:] < 0.5] = 1
    print("Positive Instances ", np.sum(y_true == 1))
    score = f1_score(y_true, y_pred, average='macro')
    print ("F1 Score: ", score)
    return score

def get_seed(seed, c_run_id):
    """
    Compute the seed for this run, helps to reproduce the result
    :param seed:
    :param c_run_id:
    :return:
    """
    return seed + c_run_id * 100

def parse_arguments():
    """parse all the arguments"""
    parser = ArgumentParser()
    parser.add_argument("--filedir", action="store", default="",
                        help="Folder for input files")
    parser.add_argument("--cachedir", action="store", default="",
                        help="Folder where the generated models will be cached for efficiency")
    parser.add_argument("--plotsdir", action="store", default="",
                        help="Folder for output plots")
    parser.add_argument("--resultsdir", action="store", default="",
                        help="Folder where the generated metrics will be stored")
    parser.add_argument("--train_years", action="store", type=int, default=1,
                        help="determine the training years")
    parser.add_argument("--datafile", type=str, default="", required=False,
                        help="Original data in CSV format. This is used when runtype is 'regular'")
    parser.add_argument("--header", action="store_true", default=True,
                        help="Whether input file has header row")
    parser.add_argument("--startcol", action="store", type=int, default=2,
                        help="Starting column (1-indexed) for data in input CSV")
    parser.add_argument("--val_frac", action="store", type=float, default=0.1,
                        help="What fraction to use for validation")
    parser.add_argument("--seed", action="store", type=int, default=5,
                        help="random seed to use for this evaluation")
    parser.add_argument("--base_clf", action="store", type=str, default="RF",
                        help="classifier to use for this evaluation")
    parser.add_argument("--find_top", action="store", type=int, default=200,
                        help="find anomalies in top 'n' data points")
    parser.add_argument("--n_query", action="store", type=int, default=100,
                        help="how many queries we will ask in total")
    parser.add_argument("--query_budget_per_window", action="store", type=int, default=50,
                        help="how many queries we will ask per window")
    parser.add_argument("--with_feedback", action="store", type=int, default=1,
                        help="Are we considering the feedbacks?")
    parser.add_argument("--query_strategy", action="store", type=int, default=0,
                        help="Are we considering the feedbacks?")
    parser.add_argument("--starting", action="store", type=int, default=0,
                        help="only pre-train (0), feed-backed model(1), or full data(2)?")
    parser.add_argument("--weighted_update", action="store", type=int, default=0,
                        help="wighted update based on the KL divergence")
    parser.add_argument("--debug", action="store_true", default=True,
                        help="Whether to enable output of debug statements")
    parser.add_argument("--log_file", type=str, default="", required=False,
                        help="File path to debug logs")
    parser.add_argument("--n_runs", type=int, default=1, required=False,
                        help="running experiment multiple times")
    parser.add_argument("--vary_param", type=int, default=0, required=False,
                        help="which one is the varying params when we want to plot acorss years")


    return parser.parse_args()
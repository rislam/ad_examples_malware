import numpy as np
import matplotlib
matplotlib.use('Agg')
import time

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix
from math import floor
from common.utils import *
import matplotlib.pyplot as plt
from baseline.malware.baseline_util import *
from baseline.malware.baseline_experiments import process_options
from os import listdir
from os.path import isfile, join
from numpy import genfromtxt
from aad.data_stream import *
from baseline.malware.baseline_experiments import MalwareDataStream
from pprint import *


def collect_results(opts, adr=False, f1=False, queried=False):
    if f1 is True:
        key = "f1.txt"
    elif adr is True:
        key = "adr.txt"
    elif queried is True:
        key = "queried.txt"
    res_dir = os.path.join(opts.save_results_location, opts.prefix)
    result_files = [f for f in listdir(res_dir) if isfile(join(res_dir, f)) and key in f]
    # print (result_files)

    if f1 is True or adr is True:
        map_mean = {}
        map_std = {}
        print("#of files ", len(result_files))
        for file in result_files:
            act_loc = os.path.join(res_dir, file)

            n_key = len(opts.prefix)
            key = file.replace(".txt", "")[n_key + 1:]
            print(key)
            r = genfromtxt(act_loc, delimiter=',')
            # print (r)
            # print(r.shape)
            # print(opts)
            mean = np.mean(r, axis=0)
            std = np.std(r, axis=0)

            if key not in map_mean.keys():
                map_mean[key] = mean
            if key not in map_std.keys():
                map_std[key] = std
        # print("###########################")
        # print (map_mean.keys(), map_mean)
        # print("###########################")
        return map_mean, map_std
    elif queried is True:
        map_mean = {}
        map_std = {}
        map_discovered_mean = {}
        map_discovered_std = {}
        for file in sorted(result_files):
            act_loc = os.path.join(res_dir, file)
            print("#reading file: ", file)
            n_key = len(opts.prefix)
            key = file.replace(".txt", "")[n_key + 1:]
            print(key)
            r = genfromtxt(act_loc, delimiter=',')
            print(r.shape)
            # diversity_in_queries(r, opts)
            # query_baseline(opts, r)
            mean, std, mean_discovered, std_discovered = annotation_effort(opts, r, int(key.split("-")[0]))
            if key not in map_mean.keys():
                map_mean[key] = mean
            if key not in map_std.keys():
                map_std[key] = std

            if key not in map_mean.keys():
                map_discovered_mean[key] = mean_discovered
            if key not in map_std.keys():
                map_discovered_std[key] = std_discovered
        return map_mean, map_std, map_discovered_mean, map_discovered_std


def annotation_effort(opts, r, key=2012):
    datafile = opts.datafile
    label_path = datafile[:datafile.rfind("_")]
    label_file = label_path + "_orig_labels.csv"
    label_info = pd.read_csv(label_file, delimiter=',', header=0)
    labels = label_info.values[:, 0]

    r = r.astype(int)
    n_queries = r.shape[1]
    labels[labels == 'anomaly'] = 1
    labels[labels == 'nominal'] = 0
    indexes = [i for i in range(0, n_queries, int(n_queries * 1.0 / 25))]
    mean_queried = list()
    std_queried = list()
    mean_discovered = list()
    std_discovered = list()

    opts.labelindex = 1
    X_full, y_full = read_data_as_matrix(opts)
    stream = MalwareDataStream(X_full, y_full, IdServer(initial=0))
    pt = stream.read_next_from_stream()
    x_init, y_init, _ = pt.x, pt.y, pt.ids
    yr = 2011
    while not stream.empty():
        yr += 1
        i_curr = stream.read_next_from_stream()
        if yr != key:
            continue
        x, y, ids = i_curr.x, i_curr.y, i_curr.ids
        mean_queried_yr = list()
        mean_discovered_yr = list()
        n_malware = np.sum(y)
        for r_id in range(opts.n_runs):
            seed = get_seed(opts.seed, r_id)
            mean_queried_ = list()
            mean_discovered_ = list()
            for ind in indexes:
                c_indexes = r[r_id, :ind]
                queried_x = x[np.where(np.in1d(ids, c_indexes))]
                queried_y = y[np.where(np.in1d(ids, c_indexes))]
                n_queried_x = x[np.where(~np.in1d(ids, c_indexes))]
                n_queried_y = y[np.where(~np.in1d(ids, c_indexes))]
                assert queried_x.shape[0] + n_queried_x.shape[0] == x.shape[0]
                assert np.sum(queried_y) + np.sum(n_queried_y) == np.sum(y)
                train_x = np.vstack((x_init, queried_x))
                queried_malware = np.sum(queried_y) * 1.0 / n_malware
                # print("queried malware ", queried_malware, end=" ")
                train_y = np.hstack((y_init, queried_y))
                identified_malware = reconstruct_classifier(train_x, train_y, n_queried_x, n_queried_y, seed) * 1.0 / \
                                     n_malware
                mean_queried_.append(queried_malware)
                mean_discovered_.append(identified_malware)
            mean_queried_yr.append(mean_queried_)
            mean_discovered_yr.append(mean_discovered_)

        mean_queried.append(np.mean(mean_queried_yr, axis=0))
        std_queried.append(np.std(mean_queried_yr, axis=0))
        mean_discovered.append(np.mean(mean_discovered_yr, axis=0))
        std_discovered.append(np.std(mean_discovered_yr, axis=0))

        print("#################")
        print(mean_queried, std_queried)
        print("#################")
        # for ind in indexes:
        #     mean.append(np.sum(labels[r[:, :ind]])/opts.n_runs)
        #     std.append(np.std(np.sum(labels[r[:, :ind]], axis=1)))

    return mean_queried, std_queried, mean_discovered, std_discovered

def reconstruct_classifier(train_x, train_y, test_x, test_y, seed):
    """
    :param data: contains x, y, ids
    :param indexes: is the list of location where we want to evaluate [0%, 1%, ... 25%]
    :return: no of anomalies identified
    """
    estimator = RandomForestClassifier(n_estimators=100, random_state=seed)
    estimator.fit(train_x, train_y)
    tn, fp, fn, tp = confusion_matrix(test_y, estimator.predict(test_x)).ravel()
    identified_malware = tp
    # print("tp: ", tp, " fraction: ", identified_malware)
    return identified_malware


def query_baseline(opts, queries=None):
    """Compute the query Baseline"""
    datafile = opts.datafile
    label_path = datafile[:datafile.rfind("_")]
    label_file = label_path + "_orig_labels.csv"
    label_info = pd.read_csv(label_file, delimiter=',', header=0)
    labels = label_info.values[:, 1]

    for current_run_id in range(opts.n_runs):
        datafile = join(opts.filedir, "fullsamples", opts.datafile)
        opts.labelindex = 1
        X_full, y_full = read_data_as_matrix(opts)
        seed = opts.seed + current_run_id * 100
        print("seed ", seed)
        stream = MalwareDataStream(X_full, y_full, IdServer(initial=0))
        pt = stream.read_next_from_stream()
        x_init, y_init, _ = pt.x, pt.y, pt.ids
        estimator = RandomForestClassifier(n_estimators=100, random_state=seed)
        estimator.fit(x_init, y_init)
        while not stream.empty():
            i_curr = stream.read_next_from_stream()
            x, y, ids = i_curr.x, i_curr.y, i_curr.ids
            y_pred = estimator.predict_proba(x)
            data = np.hstack((x, y.reshape(-1, 1), ids.reshape(-1, 1)))
            # print ("data shape ", data.shape)
            result = np.hstack((y_pred[:, 1].reshape(-1, 1), y.reshape(-1, 1), ids.reshape(-1, 1)))
            result = result[result[:, 0].argsort()[::-1]]
            n_anomalies = np.sum(result[:, 1], axis=0)
            adr_result = np.sum(result[result[:, 0] >= 0.5, 1], axis=0)
            print(adr_result, n_anomalies)
            # print("qids ", result[result[:, 0] >= 0.5, 2][:5])
            find_families_count(labels, result[result[:, 0] >= 0.5, 2])
            init_size = x_init.shape[0]
            n_pool = x.shape[0]
            if queries is not None:
                q = queries[current_run_id]
                percentage_list = [i for i in range(0, int(n_pool / 20), int(n_pool / 100))]
                for i in range(int(n_pool / 20), int(n_pool / 4) + 1, int(n_pool / 20)):
                    percentage_list.append(i)
                print(percentage_list)
                counter = 0
                n_malware_found = 0
                for idx in q:
                    x_init = np.vstack((x_init, data[data[:, -1] == idx, :-2]))
                    y_init = np.hstack((y_init, data[data[:, -1] == idx, -2]))
                    # print(np.where(data[:, -1] == idx))
                    if data[data[:, -1] == idx, -2] == 1:
                        n_malware_found += 1

                    data = np.delete(data, np.where(data[:, -1] == idx), axis=0)
                    # y = np.delete(y, np.where(data[:, -1] == idx))[:, -2]
                    # ids = np.delete(ids, np.where(ids == idx))
                    # if not (data.shape[0] == y.shape[0] and ids.shape[0] == y.shape[0]):
                    #     print("x, y, ids " , x.shape[0], y.shape[0], ids.shape[0])
                    #     print(data[data[:, -1] == idx, -2:])
                    #     print(idx)

                    counter += 1
                    # print ("X_Y init ", x_init.shape, y_init.shape, " x, y: ", x.shape, y.shape)
                    # print("added ", x_init.shape[0] - init_size, " ", x.shape[0])
                    if counter in percentage_list:
                        print(n_malware_found, end=",")
                        # print(counter)
                        # print ("X_Y init ", x_init.shape, y_init.shape, " data: ", data.shape[0])
                        # print("queried familes ", find_families_count(labels, q[:counter]))

                        estimator.fit(x_init, y_init)
                        y_pred = estimator.predict_proba(x)
                        # print(y_pred.shape[0], " ", ids.shape)
                        result = np.hstack((y_pred[:, 1].reshape(-1, 1), y.reshape(-1, 1), ids.reshape(-1, 1)))
                        result = result[result[:, 0].argsort()[::-1]]
                        n_anomalies = np.sum(result[:, 1], axis=0)
                        adr_result = np.sum(result[result[:, 0] >= 0.5, 1], axis=0)
                        print(adr_result, n_anomalies, result.shape)
                        print("qids ", result[result[:, 0] >= 0.5, 2][:5])
                        l = np.hstack((result[result[:, 0] >= 0.5, 2], q[:counter]))
                        print("predicted familes ", find_families_count(labels, l))
            # break
        # break


def find_families_count(labels, qids):
    fam_set = set()
    for qid in qids:
        fam_set.add(labels[int(qid)])
    # print("# of families ", len(fam_set))
    return len(fam_set)


def diversity_in_queries(q, opts):
    datafile = opts.datafile
    label_path = datafile[:datafile.rfind("_")]
    label_file = label_path + "_orig_labels.csv"
    label_info = pd.read_csv(label_file, delimiter=',', header=0)
    labels = label_info.values[:, 1]
    n_runs = q.shape[0]
    n_batch = 3
    sum_run = 0
    dis_fam = 0

    for r in range(n_runs):
        n_q = q[r].shape[0]
        if opts.qsname == "diverse_query_strategy":
            n_q = floor(n_q/n_batch)
            print("n_q ", n_q)
        set_count = 0
        family_set = set()
        for qidx in range(0, n_q, n_batch):
            qlabels = labels[qidx : qidx + n_batch]
            set_count += len(set(qlabels))
            family_set.update(qlabels)
        sum_run += (set_count/(n_q/n_batch))
        # print("discovered fam ", len(family_set))
        dis_fam += len(family_set)
    print(dis_fam * 1.0 /n_runs)


def plot_map(opts, result_map, std_map=None, f1=False, adr=False):
    print("inside plot map")
    starting_yr = 2012
    ending_yr = 2017
    if f1 is True:
        suffix = "-f1"
        title = "F1 Score across years"
        y_label = "F1 Score"
        x_label = "Years"
    elif adr is True:
        suffix = "-adr"
        title = "Detection Rate across years"
        y_label = "Detection Rate"
        x_label = "Years"
    keys = result_map.keys()

    for s_yr in range(starting_yr, ending_yr):
        plt_keys = list()
        plt_values = list()
        plt_stds = list()

        for e_yr in range(s_yr, ending_yr):
            res_key = str(s_yr) + "_" + str(e_yr) + suffix
            if res_key in keys:
                print(res_key, result_map[res_key])
                n_key_res = len(result_map[res_key])
                plt_keys.append(res_key.replace(suffix, "").split("_")[1])
                plt_values.append(result_map[res_key])
                plt_stds.append(std_map[res_key])
        print(plt_keys, plt_values, len(plt_keys))
        objects = plt_keys
        y_pos = np.arange(len(objects))
        performance = plt_values
        ax = plt.subplot(111)
        w = 0.1
        plt_values_np = np.array(plt_values)
        plt_stds_np = np.array(plt_stds)
        print(plt_values_np, plt_stds_np)

        ax.errorbar(y_pos, plt_values_np[:, 0], yerr=plt_stds_np[:, 0])
        print(plt_values_np[:, 0])
        plt.xticks(y_pos, objects)
        plt.xlabel(x_label)
        plt.ylabel(y_label)
        plt.title(title + "-" + str(s_yr))
        plt.show()
        # plt.savefig(os.path.join("./results", opts.prefix + "-" + str(s_yr) + suffix + ".pdf"))
        # plt.close()


def plot_feedback(opts, result_map, std_map=None, f1=False, adr=False, adapt=False, multiple=False, v_list=None, weight=False,
                  query=False, bar_mean=None, bar_std=None):
    print("inside plot feedback")
    starting_yr = 2012
    ending_yr = 2017
    if f1 is True:
        suffix = "-f1"
        title = "F1 Score change with feedback for "
        y_label = "F1 Score"
        x_label = r"$\beta$ (% of dataset queried)"
    elif adr is True:
        suffix = "-adr"
        title = "Detection Rate change with feedback for "
        y_label = "Detection Rate"
        x_label = r"$\beta$ (% of dataset queried)"
    elif query is True:
        suffix = "-queried"
        title = "Malware identification effort "
        y_label = "#of malwares"
        x_label = r"$\beta$ (% of dataset queried)"
    keys = result_map.keys()
    print(keys)

    if adapt is True:
        plt_keys = list()
        plt_values = list()
        plt_stds = list()
        for s_yr in range(starting_yr, ending_yr):
            fair_key = str(s_yr) + "_" + str(s_yr) + "_fair_eval" + suffix
            data = result_map[str(s_yr) + "_" + str(s_yr) + suffix][0]
            plt_values.append(np.insert(result_map[fair_key], 0, data))
            plt_stds.append(np.insert(std_map[fair_key], 0, 0))
            plt_keys.append(str(s_yr) + "-fair")

            optmst_key = str(s_yr) + "_" + str(s_yr) + "_optmst_eval" + suffix
            plt_values.append(np.insert(result_map[optmst_key], 0, data))
            plt_keys.append(str(s_yr) + "-optmst")
            plt_stds.append(np.insert(std_map[fair_key], 0, 0))

        objects = plt_keys
        y_pos = np.arange(0, 5, 1)
        for yidx in range(5, 26, 5):
            y_pos = np.append(y_pos, yidx)

        performance = plt_values
        ax = plt.subplot(111)
        print("n_object ", len(objects), " len plt values ", len(plt_values[0]))
        colors = ['r', 'b', 'g', 'k', 'm']
        for i in range(len(objects)):
            print(y_pos)
            print(plt_values[i])
            if "_" in plt_keys[i]:
                label = plt_keys[i].split("_")[1]
                ls = "--"
            elif "fair" in plt_keys[i]:
                ls = "-"
                label=plt_keys[i]
            else:
                label = plt_keys[i]
                ls = '--'
            if "-" in label:
                c_y = int(plt_keys[i].split("-")[0])
                if c_y == 2012:
                    c = 'c'
                elif c_y == 2013:
                    c = 'r'
                elif c_y == 2014:
                    c = 'b'
                elif c_y == 2015:
                    c = 'm'
                elif c_y == 2016:
                    c = 'g'
            ax.errorbar(y_pos, plt_values[i][y_pos], yerr=plt_stds[i][y_pos], marker='o', markersize=4,
                        linestyle=ls, label=label, c=c)
        tick_label = list()
        for ti in range(0, 5, 1):
            tick_label.append(str(ti))
        for ti in range(5, 26, 5):
            tick_label.append(str(ti))
        plt.xticks(y_pos, tick_label, fontsize=14)
        plt.yticks(np.arange(0, 1.01, 0.2), fontsize=14)
        plt.xlabel(x_label, fontsize=20)
        plt.ylabel(y_label, fontsize=20)
        # plt.title("Adaptation with the feedbacks")
        plt.legend(ncol=2, prop={'size': 13})
        # plt.show()
        plt.savefig(os.path.join("./results", opts.prefix + "-" + str(s_yr) + suffix + "-adaptation.pdf"),bbox_inches='tight')
        plt.close()
    elif multiple is True:
        plt_keys = list()
        plt_values = list()
        plt_stds = list()
        dis_plt_values = list()
        dis_plt_stds = list()
        if query is True:
            plt_keys = sorted(keys)
            for k in plt_keys:
                plt_values.append(result_map[k])
                plt_stds.append(std_map[k])
                if bar_mean is not None:
                    dis_plt_values.append(bar_mean[k])
                    dis_plt_stds.append(bar_std[k])


            plt_values = np.array(plt_values)
            plt_stds = np.array(plt_stds)
            s_yr = "2010"
        else:

            for s_yr in range(starting_yr, ending_yr):
                for vidx in v_list:
                    fair_key = str(s_yr) + "_" + str(s_yr) + "_fair_eval" + suffix + "-" + str(vidx)
                    data = result_map[str(s_yr) + "_" + str(s_yr) + suffix + "-" + str(vidx)][0]
                    plt_values.append(np.insert(result_map[fair_key], 0, data))
                    plt_stds.append(np.insert(std_map[fair_key], 0, 0))
                    plt_keys.append(str(s_yr) + "-fair" + "-" + str(vidx))

                # optmst_key = str(s_yr) + "_" + str(s_yr) + "_optmst_eval" + suffix + "-" + str(vidx)
                # plt_values.append(np.insert(result_map[optmst_key], 0, data))
                # plt_keys.append(str(s_yr) + "-optmst")
                # plt_stds.append(np.insert(std_map[fair_key], 0, 0))

        objects = plt_keys
        # y_pos = np.arange(0, 26)
        y_pos = np.arange(0, 5, 1)
        for yidx in range(5, 26, 5):
            y_pos = np.append(y_pos, yidx)
        performance = plt_values
        ax = plt.subplot(111)
        print("n_object ", len(objects), " len plt values ", len(plt_values[0]))
        print("plt keys ", plt_keys)
        colors = ['r', 'b', 'g', 'k', 'm', 'y', 'c', 'peru', 'orchid', 'lime']

        for i in range(len(objects)):
            # print(y_pos, type(y_pos))
            # print(plt_values[i], type(plt_values[i]))
            if True or "fair" in plt_keys[i]:
                label = plt_keys[i][:plt_keys[i].rfind("-")]
                vidx = int(plt_keys[i].split("-")[-1])
                if vidx == 0:
                    ls = "--"
                    if weight is True:
                        label += "-W/O"
                    elif query is True:
                        label += "-US"
                elif vidx == 1:
                    ls = '-'
                    if weight is True:
                        label += "-W"
                    elif query is True:
                        label += "-GQ"
                elif vidx == 2:
                    ls = '--'
                    if query is True:
                        label += "-DvQ"
                # label=plt_keys[i]
            else:
                label = plt_keys[i]
                ls = '--'
            if "-" in label:
                c_y = int(plt_keys[i].split("-")[0])
                if c_y == 2012:
                    c = 'c'
                elif c_y == 2013:
                    c = 'r'
                elif c_y == 2014:
                    c = 'b'
                elif c_y == 2015:
                    c = 'm'
                elif c_y == 2016:
                    c = 'g'
            print(label)
            print("len: ", len(plt_values[i]))
            # print(plt_values)
            # print(plt_stds)
            if len(plt_values[i]) == 11:
                print("diversity plot-----------------")
                y_pos = np.arange(0, 10, 1)

                print(y_pos, len(y_pos))
                ax.errorbar(y_pos, plt_values[i][:-1], yerr=plt_stds[i][:-1], marker='o', markersize=4,
                            linestyle=ls, label=label, c=c)
            else:
                print("else ", y_pos)
                print(plt_values[i])
                ax.errorbar(y_pos, plt_values[i][y_pos], yerr=plt_stds[i][y_pos], marker='o', markersize=4,
                            linestyle=ls, label=label, c=c)
                ax.bar(y_pos, plt_values[i][y_pos], width=0.35, yerr=plt_stds[i][y_pos], label=label)
                if bar_mean is not None:
                    ax.bar(y_pos, dis_plt_values[i][y_pos], width=0.35, bottom=plt_values[i][y_pos],
                           yerr=dis_plt_stds[i][y_pos], label=label)
        tick_label = list()
        for ti in range(0, 5, 1):
            tick_label.append(str(ti))
        for ti in range(5, 26, 5):
            tick_label.append(str(ti))
        # for ti in range(0, 26, 1):
        #     tick_label.append(str(ti))
        plt.xticks(y_pos, tick_label, fontsize=14)
        # plt.yticks(np.arange(0, 1.01, 0.2), fontsize=14)
        plt.xlabel(x_label, fontsize=20)
        plt.ylabel(y_label, fontsize=20)
        # plt.ylim(0, 1)
        # plt.title("Diversed vs Uncertainty based querying scheme comparison")
        plt.legend(ncol=2, prop={'size': 13})
        # plt.show()

        plt.savefig(os.path.join("./results", opts.prefix + "-" + str(s_yr) + suffix + "-US-DQ-weighted.pdf"), bbox_inches='tight')

        # plt.savefig(os.path.join("./results", opts.prefix + "-" + str(s_yr) + suffix + "-US-DQ.pdf"))
        plt.close()
    else:  # generalizability
        for s_yr in range(starting_yr, ending_yr):
            plt_keys = list()
            plt_values = list()
            plt_stds = list()
            fair_key = str(s_yr) + "_" + str(s_yr) + "_fair_eval" + suffix
            data = result_map[str(s_yr) + "_" + str(s_yr) + suffix][0]
            plt_values.append(np.insert(result_map[fair_key], 0, data))
            plt_stds.append(np.insert(std_map[fair_key], 0, 0))
            plt_keys.append("fair")

            optmst_key = str(s_yr) + "_" + str(s_yr) + "_optmst_eval" + suffix
            plt_values.append(np.insert(result_map[optmst_key], 0, data))
            plt_keys.append("optmst")
            plt_stds.append(np.insert(std_map[fair_key], 0, 0))
            for e_yr in range(s_yr + 1, ending_yr):
                res_key = str(s_yr) + "_" + str(e_yr) + suffix
                if res_key in keys:
                    print(res_key, result_map[res_key])
                    n_key_res = len(result_map[res_key])
                    plt_keys.append(res_key.replace(suffix, ""))
                    plt_values.append(result_map[res_key])
                    plt_stds.append(std_map[res_key])

            objects = plt_keys
            # y_pos = np.arange(0, 6)
            y_pos = np.arange(0, 5, 1)
            for yidx in range(5, 26, 5):
                y_pos = np.append(y_pos, yidx)
            performance = plt_values
            ax = plt.subplot(111)
            w = 0.1
            # plt_values_np = np.array(plt_values)
            # plt_stds_np = np.array(plt_stds)
            print(plt_values_np)


            for i in range(len(objects)):
                print(y_pos)
                print(plt_values[i])
                if "_" in plt_keys[i]:
                    label = "$\\upsilon=$" + str(plt_keys[i].split("_")[1])
                    ls = "-"

                else:
                    label = plt_keys[i]
                    ls = '--'
                    if label == 'fair':
                        c = 'darkorange'
                    else:
                        c = 'royalblue'
                if "_" in plt_keys[i]:
                    c_y = int(plt_keys[i].split("_")[1])
                    if c_y == 2013:
                        c = 'r'
                    elif c_y == 2014:
                        c = 'b'
                    elif c_y == 2015:
                        c = 'm'
                    elif c_y == 2016:
                        c = 'g'
                ax.errorbar(y_pos, plt_values[i][y_pos], yerr=plt_stds[i][y_pos], marker='o', markersize=4,
                linestyle=ls, label=label, c=c)
            # for i in range(0, n_key_res):
            #     adjusted_x = i - (n_key_res/2)
            #     ax.errorbar(y_pos + adjusted_x * w, plt_values_np[:, i], align='center', width=w, yerr=plt_stds_np[:, i])
            #     print(plt_values_np[:, i])
            tick_label = list()
            # for ti in range(0, 26, 5):
            #     tick_label.append(str(ti))
            for ti in range(0, 5, 1):
                tick_label.append(str(ti))
            for ti in range(5, 26, 5):
                tick_label.append(str(ti))
            plt.xticks(y_pos, tick_label, fontsize=18)
            plt.yticks(fontsize=18)
            plt.xlabel(x_label, fontsize=20)
            plt.ylabel(y_label, fontsize=20)
            plt.ylim(0, 1)
            # plt.title(title + str(s_yr))
            plt.legend(ncol=2, prop={'size': 18})
            # plt.show()
            plt.savefig(os.path.join("./results", opts.prefix + "-" + str(s_yr) + suffix + "-feedback.pdf"), bbox_inches='tight')
            plt.close()


def plot_results(opts):

    start = time.time()

    print("save location ", opts.save_results_location)
    f1_mean, f1_std = collect_results(opts, f1=True)
    adr_mean, adr_std = collect_results(opts, adr=True)
    # collect_results(opts, queried=True)

    # plot_map(opts, f1_mean, f1_std, f1=True)
    # plot_map(opts, adr_mean, adr_std, adr=True)
    plot_feedback(opts, f1_mean, f1_std, f1=True, adapt=True)
    plot_feedback(opts, adr_mean, adr_std, adr=True, adapt=True)
    # plot_feedback(opts, f1_mean, f1_std, f1=True)
    # plot_feedback(opts, adr_mean, adr_std, adr=True)

    end = time.time()
    logger.debug("##Finished all %d runs in %.2f min(s)##" % (opts.n_runs, (end - start) / 60.0))


def multi_plot_results():
    """When we want to compute results acorss different experiment settings"""
    opts = parse_arguments()

    if opts.vary_param == 0:
        param_change="weight"
    elif opts.vary_param == 1:
        param_change="independent"
    elif opts.vary_param == 2:
        param_change="feedbacked"

    f1_mean_map = {}
    f1_std_map = {}
    adr_mean_map = {}
    adr_std_map = {}

    if opts.vary_param == 0:
        list_of_params = [0, 1]

        for i in list_of_params:
            opts.weighted_update = i
            key = "W-" + str(opts.weighted_update)
            opts = process_options(opts)
            f1_mean, f1_std = collect_results(opts, f1=True)
            adr_mean, adr_std = collect_results(opts, adr=True)
            line_plt_map(f1_mean, key)
            f1_mean_map[key] = f1_mean
            f1_std_map[key] = f1_std
            adr_mean_map[key] = adr_mean
            adr_std_map[key] = adr_std
        plt.show()
        print(f1_mean_map)

def line_plt_map(map, prefix=None, plot=None):
    param_keys = map.keys()
    for pkey in param_keys:
        res_map = map[pkey]
        res_keys = res_map.keys()
        for key in res_keys:
            plt.plot(map[key], label=prefix + key)
    plt.legend()
    plt.show()


def compute_class_diversity():
    start = time.time()
    opts = parse_arguments()
    # qs = [2, 0]
    # f1_mean_complete = {}
    # f1_std_complete = {}
    # adr_mean_complete = {}
    # adr_std_complete = {}
    # for i in qs:
    #     opts.query_strategy = i
    #     opts = process_options(opts)
    #     configure_logger(opts)
    #     # collect_results(opts, queried=True)
    #     f1_mean, f1_std = collect_results(opts, f1=True)
    #     for k in f1_mean.keys():
    #         f1_mean_complete[k + "-" + str(i)] = f1_mean[k]
    #     for k in f1_std.keys():
    #         f1_std_complete[k + "-" + str(i)] = f1_std[k]
    #
    #     adr_mean, adr_std = collect_results(opts, adr=True)
    #     for k in adr_mean.keys():
    #         adr_mean_complete[k + "-" + str(i)] = adr_mean[k]
    #     for k in adr_std.keys():
    #         adr_std_complete[k + "-" + str(i)] = adr_std[k]
    #
    # plot_feedback(opts, f1_mean_complete, f1_std_complete, f1=True, multiple=True, v_list=qs, query=True)
    # plot_feedback(opts, adr_mean_complete, adr_std_complete, adr=True, multiple=True, v_list=qs, query=True)

    f1_mean_complete = {}
    f1_std_complete = {}
    adr_mean_complete = {}
    adr_std_complete = {}
    malware_mean_complete = {}
    malware_std_complete = {}
    malware_mean_discovered = {}
    malware_std_discovered = {}
    qs = [0, 1]
    for i in qs:
        opts.weighted_update = i
        opts = process_options(opts)
        configure_logger(opts)
        # collect_results(opts, queried=True)
        f1_mean, f1_std = collect_results(opts, f1=True)
        for k in f1_mean.keys():
            f1_mean_complete[k + "-" + str(i)] = f1_mean[k]
        for k in f1_std.keys():
            f1_std_complete[k + "-" + str(i)] = f1_std[k]

        adr_mean, adr_std = collect_results(opts, adr=True)
        for k in adr_mean.keys():
            adr_mean_complete[k + "-" + str(i)] = adr_mean[k]
        for k in adr_std.keys():
            adr_std_complete[k + "-" + str(i)] = adr_std[k]

        malware_mean, malware_std, mal_dis_mean, mal_dis_std = collect_results(opts, queried=True)
        for k in malware_mean.keys():
            malware_mean_complete[k + "-" + str(i)] = malware_mean[k]
        for k in malware_std.keys():
            malware_std_complete[k + "-" + str(i)] = malware_std[k]

    pprint(malware_mean_complete)
    # plot_feedback(opts, f1_mean_complete, f1_std_complete, f1=True, multiple=True, v_list=qs, weight=True)
    # plot_feedback(opts, adr_mean_complete, adr_std_complete, adr=True, multiple=True, v_list=qs, weight=True)
    plot_feedback(opts, malware_mean_complete, malware_std_complete, query=True, multiple=True, v_list=qs, weight=True,
                  bar_mean=None, bar_std=None)
    # end = time.time()
    # print("time needed %f" % (end-start))

# pythonw -m baseline.malware.prepare_plots --filedir "" --datafile "/Users/mislam1/Documents/RA/research-2018/ad_rakib/ad_examples/datasets/anomaly/malware-complete/fullsamples/malware-complete_1.csv" --query_strategy 0 --n_query 2000 --n_runs 10 --weighted_update 1 --starting 0 --vary_param 0

if __name__ == '__main__':
    # main run this one
    opts = parse_arguments()

    opts = process_options(opts)
    configure_logger(opts)
    plot_results(opts)

    # secondary code runs
    compute_class_diversity()
    # multi_plot_results()
    # opts = parse_arguments()
    # query_baseline(opts)
    # collect_results(opts, queried=True)